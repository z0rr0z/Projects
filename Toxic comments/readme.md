# Определение тональности комментариев

[ipynb](toxic_comments.ipynb)

## Цель и задачи исследования

**Заказчик исследования:** интернет-магазин.

**Цель:** построить модель для классификации комментариев к товарам на позитивные и негативные.

**Критерий качества модели**: метрика *F1* не меньше 0.75.

**Задачи (этапы) исследования:**
1. Провести загрузку и общий обзор данных.
2. Повести подготовку данных для моделей TF-IDF.
3. Построить модели классификации комментариев.
4. Построить модель на основе BERT.
5. Сформулировать общие выводы.

## Навыки и инструменты

- **Python**
- **Pandas**
- **NLP (NTLK, TF-IDF, BERT)**
- **PyTorch**
- **Transformers**
- **Scikit-learn**
- **LightGBM**
- **Matplotlib**
- **Seaborn**

## Общий вывод

Мы построили разные модели классификации комментариев к товарам на позитивные и негативные и выбрали из них лучшую.

В том числе мы:
1. Провели загрузку и общий обзор данных, установили наличие дисбаланса по целевому признаку.
2. Построили модели на основе TF-IDF:
- провели лемматизацию и векторизацию;
- перебрали гиперпараметры для нескольких моделей (логичтическая регрессия и Light GBM);
- установили, что лучшей моделью является логистическая регрессия с l2-регуляризацией, которая показала *F1* = 0.7656 на тестовой выборке, что выше целевого значения.
3. Построили модель на основе BERT:
- провели токенизацию и сформировали эмбеддинги;
- используя логистическую регрессию, построили модель классификации, которая показала *F1* = 0.9462 на тестовой выборке, что значительно выше целевого значения.

Таким образом, лучшей моделью стала модель на основе BERT. Однако у нее есть недостаток: долгое обучение.

**Рекомендация заказчику:**
- взять на вооружение полученные модели;
- в зависимости от конкретной задачи можно использовать разные модели: для быстрой (но не всегда точной) оценки тональности - модель на основе TF-IDF, для значительно более точной - модель на основе BERT.
